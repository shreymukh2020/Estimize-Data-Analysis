{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium==3.141.0 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from selenium==3.141.0) (1.25.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium==3.141.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\shrey\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: requests in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.24.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from webdriver-manager) (5.1.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2020.6.20)\n",
      "Requirement already satisfied: colorama in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the chrome driver by passing some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.headless = False\n",
    "browser = webdriver.Chrome(executable_path = 'C:/Users/shrey/Downloads/chromedriver_win32/chromedriver.exe',\n",
    "                          options = chrome_options)\n",
    "url_head = 'https://www.estimize.com/users/sign_in'\n",
    "browser.get(url_head)\n",
    "time.sleep(random.uniform(1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of getting the Estimize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filling in sign_in forms by identifying the username and password cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_in():\n",
    "    url = 'https://www.estimize.com/users/sign_in'\n",
    "    browser.get(url)\n",
    "\n",
    "\n",
    "    \n",
    "    email_field = browser.find_element_by_id('user_login')\n",
    "    password_field = browser.find_element_by_id('user_password')\n",
    "    submit_btn = browser.find_element_by_xpath('//input[@type=\"submit\"]')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    username = 'shubmukh@gmail.com'\n",
    "    password = 'Shubhomoy_2010'\n",
    "    \n",
    "    \n",
    "\n",
    "    email_field.send_keys(username)\n",
    "    password_field.send_keys(password)\n",
    "    submit_btn.click()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Estimize website for getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.glassdoor.com/Overview/Working-at-ADC-Telecommunications-EI_IE1075.11,33.htm'\n",
    "\n",
    "tickers = ['A', 'AA', 'AACH', 'AAL', 'AAN', 'AAOI', 'AAON', 'AAP', 'AAPL', 'AAWW', 'AAXN','ABBV', 'ABC', 'ABEO', 'ABG','ABM','ABMD', 'ABT', \n",
    "           'ACA', 'ACAD', 'ACB', 'ACCO', 'LULU', 'ACET', 'ACHC', 'ACIA', 'ACIW', 'ACLS','ACM','ACN','ACOR','ACRX', 'ACTG', 'ADAP',\n",
    "           'ADBE', 'ADI','ADM','ADMS', 'ADP', 'ADS', 'ADSK', 'ADSW', 'ADTN',  'ADUS', 'AEE', 'AEGN', 'AEIS', 'AEL', 'AEM', 'AEO']\n",
    "\n",
    "quarters = ['fq1-2020', 'fq2-2020', 'fq3-2020', 'fq4-2020']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data for Company table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_overview(browser):\n",
    "   \n",
    "    overviewAll = {}\n",
    "\n",
    "    try:\n",
    "        for i in range(len(tickers)):\n",
    "            for j in range(len(quarters)):\n",
    "#             url = 'https://www.estimize.com/'+tickers[i]+'/fq3-2021?metric_name=eps&chart=historical'\n",
    "                url = 'https://www.estimize.com/'+tickers[i]+ '/' + quarters[j]+ '?metric_name=eps&chart=historical'\n",
    "    #     https://www.estimize.com/a/fq3-2021?metric_name=eps&chart=historical\n",
    "                browser.get(url)\n",
    "                time.sleep(1)\n",
    "                overview = {}\n",
    "                overview['quarter'] = quarters[j]\n",
    "                overview['Ticker'] = browser.find_element_by_class_name('release-header-information-title').text\n",
    "                overview['Company Name'] = browser.find_element_by_class_name('release-header-information-description').text\n",
    "                sectors = browser.find_element_by_class_name('release-header-information-breadcrumb')\n",
    "                overview['Sectors'] = sectors.text.split('›')[0]\n",
    "                overview['Industries'] = sectors.text.split('›')[1]\n",
    "                numbers = browser.find_elements_by_class_name('summary-sub-title')\n",
    "                overview['Number of Followers'] = numbers[0].text\n",
    "                overview['Number of Analysts'] = numbers[1].text\n",
    "\n",
    "                overviewAll[len(overviewAll)]=overview\n",
    "    except Exception:\n",
    "        pass\n",
    "       \n",
    "    return overviewAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Company CSV/JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_info = scrape_overview(browser)\n",
    "\n",
    "with open('Company.json', 'w') as outfile:\n",
    "    json.dump(company_info, outfile, indent=4)\n",
    "    \n",
    "df=pd.DataFrame(company_info)\n",
    "df_trans = df.T\n",
    "df_trans.to_csv('Company.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data for EPS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_eps(browser):\n",
    "    eps = {}\n",
    "#     tickers1 = ['A', 'AA' ]\n",
    "#     try:\n",
    "    for i in range(len(tickers)):\n",
    "        for j in range(len(quarters)):\n",
    "            url = 'https://www.estimize.com/'+tickers[i]+ '/' + quarters[j] + '?metric_name=eps&chart=historical'\n",
    "            browser.get(url)\n",
    "            time.sleep(1)\n",
    "            analysts_generic = browser.find_elements_by_class_name('estimates-tbl-consensus-column')\n",
    "            values_generic = browser.find_elements_by_class_name('estimates-tbl-consensus-eps')\n",
    "\n",
    "            for generic_count in range(len(analysts_generic)):\n",
    "                eps_generic = {}\n",
    "                eps_generic['quarter'] = quarters[j]\n",
    "                eps_generic['Ticker'] = browser.find_element_by_class_name('release-header-information-title').text\n",
    "                eps_generic['Company Name'] = browser.find_element_by_class_name('release-header-information-description').text\n",
    "                eps_generic['Name'] = analysts_generic[generic_count].text.split('\\n')[0]\n",
    "                eps_generic['Type'] = \"Generic\"\n",
    "                eps_generic['Estimated Value'] = values_generic[generic_count].text\n",
    "                eps [len(eps)] = eps_generic\n",
    "\n",
    "            analysts = browser.find_elements_by_class_name('username')\n",
    "            analysts_values = browser.find_elements_by_class_name('estimates-tbl-eps')\n",
    "\n",
    "            for analyst_count in range(len(analysts)):\n",
    "                eps_Analyst = {}\n",
    "                eps_Analyst['quarter'] = quarters[j]\n",
    "                eps_Analyst['Ticker'] = browser.find_element_by_class_name('release-header-information-title').text\n",
    "                eps_Analyst['Company Name'] = browser.find_element_by_class_name('release-header-information-description').text\n",
    "                eps_Analyst['Name'] = analysts[analyst_count].text\n",
    "                eps_Analyst['Type'] = \"Analyst\"\n",
    "                eps_Analyst['Estimated Value'] = analysts_values[analyst_count].text\n",
    "\n",
    "                eps [len(eps)] = eps_Analyst\n",
    "\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create EPS information Data/JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_info = scrape_eps(browser)\n",
    "\n",
    "with open('EPS.json', 'w') as outfile:\n",
    "    json.dump(eps_info, outfile, indent=4)\n",
    "\n",
    "df=pd.DataFrame(eps_info)\n",
    "df_trans = df.T\n",
    "df_trans.to_csv('EPS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates for Analyst URL List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_dup(duplicate):\n",
    "    final_list = []\n",
    "    \n",
    "    for num in range(len(duplicate)):\n",
    "        if duplicate[num] not in final_list:\n",
    "            final_list.append(duplicate[num])\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract All Analyst URLs from the Ticker Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_analysts_list(browser):\n",
    "    \n",
    "    ana_list = {}\n",
    "    for i in range(len(tickers)):\n",
    "        for j in range(len(quarters)):\n",
    "            url = 'https://www.estimize.com/'+tickers[i]+ '/' + quarters[j] + '?metric_name=eps&chart=historical'\n",
    "            browser.get(url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            #analysts = browser.find_elements_by_class_name('username')\n",
    "\n",
    "    # Get the list of all anchors for a specific Ticker\n",
    "            lnks=browser.find_elements_by_tag_name(\"a\")\n",
    "\n",
    "            # traverse list\n",
    "\n",
    "            for lnk in lnks:\n",
    "               # get_attribute() to get all href\n",
    "                if (lnk.get_attribute('href') != None):\n",
    "                    if ( '/users/' in lnk.get_attribute('href')):\n",
    "                        if ('sign_out' not in lnk.get_attribute('href')):\n",
    "                            ana_list[len(ana_list)] = lnk.get_attribute('href')\n",
    "\n",
    "    ana_list_final = Remove_dup(ana_list)\n",
    "    print (len(ana_list_final))\n",
    "\n",
    "    return ana_list_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data for Analyst table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_analysts_info(browser):\n",
    "\n",
    "    analysts_url = scrape_analysts_list(browser)\n",
    "    analyst_Profile = ['Error rate', 'Accuracy Percentile', 'Points', 'Points/Estimate', 'Stocks', 'Pending']\n",
    "    analysts_Overview_final = {}\n",
    "    for i in range(len(analysts_url)):\n",
    "        url = analysts_url[i]\n",
    "        browser.get(url)\n",
    "        time.sleep(1)\n",
    "#         print(url)\n",
    "        analyst_Overview = {}\n",
    "        try:\n",
    "            analyst_Overview['Name'] = browser.find_element_by_class_name('profile-display-name').text\n",
    "            analyst_Overview['User ID'] = browser.find_element_by_class_name('profile-username').text\n",
    "            # bio = browser.find_elements_by_class_name('profile-bio-categorizations')\n",
    "            analyst_Overview['roles'] = browser.find_element_by_class_name('profile-bio-categorizations').text\n",
    "            date = browser.find_element_by_class_name('profile-activity-stats').text.split (' ')\n",
    "            analyst_Overview['Join Date'] = date[2] + ' ' + date[3]\n",
    "            analyst_Overview['Analyst Confidence Score'] = browser.find_element_by_class_name('value').text\n",
    "\n",
    "            profile_stat = browser.find_elements_by_class_name('profile-stat')\n",
    "            for i in range (len(profile_stat)):\n",
    "                analyst_Overview[analyst_Profile[i]] = profile_stat[i].text\n",
    "           \n",
    "            analysts_Overview_final[len(analysts_Overview_final)] = analyst_Overview\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    return analysts_Overview_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Analyst Data/JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799\n"
     ]
    }
   ],
   "source": [
    "analysts_info = scrape_analysts_info(browser)\n",
    "\n",
    "with open('Analyst.json', 'w') as outfile:\n",
    "    json.dump(analysts_info, outfile, indent=4)\n",
    "\n",
    "df=pd.DataFrame(analysts_info)\n",
    "df_trans = df.T\n",
    "df_trans.to_csv('Analyst.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
