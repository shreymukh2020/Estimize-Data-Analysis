{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium==3.141.0 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from selenium==3.141.0) (1.25.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium==3.141.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\shrey\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: requests in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.24.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from webdriver-manager) (5.1.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2020.6.20)\n",
      "Requirement already satisfied: colorama in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the chrome driver by passing some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.headless = False\n",
    "browser = webdriver.Chrome(executable_path = 'C:/Users/shrey/Downloads/chromedriver_win32/chromedriver.exe',\n",
    "                          options = chrome_options)\n",
    "url_head = 'https://www.estimize.com/users/sign_in'\n",
    "browser.get(url_head)\n",
    "time.sleep(random.uniform(1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of getting the Estimize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filling in sign_in forms by identifying the username and password cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_in():\n",
    "    url = 'https://www.estimize.com/users/sign_in'\n",
    "    browser.get(url)\n",
    "\n",
    "#     email_field = browser.find_element_by_name('username')\n",
    "#     password_field = browser.find_element_by_name('password')\n",
    "#     submit_btn = browser.find_element_by_xpath('//button[@type=\"submit\"]')\n",
    "    \n",
    "    email_field = browser.find_element_by_id('user_login')\n",
    "    password_field = browser.find_element_by_id('user_password')\n",
    "    submit_btn = browser.find_element_by_xpath('//input[@type=\"submit\"]')\n",
    "\n",
    "#     with open('credentials.json') as f:\n",
    "#         d = json.loads(f.read())\n",
    "#         username = d['glassdoor'][0]['username']\n",
    "#         password = d['glassdoor'][0]['password']\n",
    "\n",
    "    username = 'shubmukh@gmail.com'\n",
    "    password = 'Shubhomoy_2010'\n",
    "    \n",
    "    \n",
    "\n",
    "    email_field.send_keys(username)\n",
    "    password_field.send_keys(password)\n",
    "    submit_btn.click()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Estimize website for getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.glassdoor.com/Overview/Working-at-ADC-Telecommunications-EI_IE1075.11,33.htm'\n",
    "\n",
    "tickers = ['A', 'AA', 'AACH', 'AAL', 'AAN', 'AAOI', 'AAON', 'AAP', 'AAPL', 'AAWW', 'AAXN','ABBV', 'ABC', 'ABEO', 'ABG','ABM','ABMD', 'ABT', \n",
    "           'ACA', 'ACAD', 'ACB', 'ACCO', 'LULU', 'ACET', 'ACHC', 'ACIA', 'ACIW', 'ACLS','ACM','ACN','ACOR','ACRX', 'ACTG', 'ADAP',\n",
    "           'ADBE', 'ADI','ADM','ADMS', 'ADP', 'ADS', 'ADSK', 'ADSW', 'ADTN',  'ADUS', 'AEE', 'AEGN', 'AEIS', 'AEL', 'AEM', 'AEO']\n",
    "\n",
    "quarters = ['fq1-2020', 'fq2-2020', 'fq3-2020', 'fq4-2020']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Overview of Ticker information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_overview(browser):\n",
    "   \n",
    "    overviewAll = {}\n",
    "\n",
    "    try:\n",
    "        for i in range(len(tickers)):\n",
    "            for j in range(len(quarters)):\n",
    "#             url = 'https://www.estimize.com/'+tickers[i]+'/fq3-2021?metric_name=eps&chart=historical'\n",
    "                url = 'https://www.estimize.com/'+tickers[i]+ '/' + quarters[j]+ '?metric_name=eps&chart=historical'\n",
    "    #     https://www.estimize.com/a/fq3-2021?metric_name=eps&chart=historical\n",
    "                browser.get(url)\n",
    "                time.sleep(1)\n",
    "                overview = {}\n",
    "                overview['quarter'] = quarters[j]\n",
    "                overview['Ticker'] = browser.find_element_by_class_name('release-header-information-title').text\n",
    "                overview['Company Name'] = browser.find_element_by_class_name('release-header-information-description').text\n",
    "                sectors = browser.find_element_by_class_name('release-header-information-breadcrumb')\n",
    "                overview['Sectors'] = sectors.text.split('›')[0]\n",
    "                overview['Industries'] = sectors.text.split('›')[1]\n",
    "                numbers = browser.find_elements_by_class_name('summary-sub-title')\n",
    "                overview['Number of Followers'] = numbers[0].text\n",
    "                overview['Number of Analysts'] = numbers[1].text\n",
    "\n",
    "                overviewAll[len(overviewAll)]=overview\n",
    "    except Exception:\n",
    "        pass\n",
    "       \n",
    "    return overviewAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Ticker Basic information and create Data/JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info = scrape_overview(browser)\n",
    "\n",
    "with open('Company', 'w') as outfile:\n",
    "    json.dump(basic_info, outfile, indent=4)\n",
    "    \n",
    "df=pd.DataFrame(basic_info)\n",
    "df_trans = df.T\n",
    "df_trans.to_csv('Company.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract EPS information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_eps(browser):\n",
    "    eps = {}\n",
    "#     tickers1 = ['A', 'AA' ]\n",
    "#     try:\n",
    "    for i in range(len(tickers)):\n",
    "        for j in range(len(quarters)):\n",
    "            url = 'https://www.estimize.com/'+tickers[i]+ '/' + quarters[j] + '?metric_name=eps&chart=historical'\n",
    "            browser.get(url)\n",
    "            time.sleep(1)\n",
    "            analysts_generic = browser.find_elements_by_class_name('estimates-tbl-consensus-column')\n",
    "            values_generic = browser.find_elements_by_class_name('estimates-tbl-consensus-eps')\n",
    "\n",
    "            for generic_count in range(len(analysts_generic)):\n",
    "                eps_generic = {}\n",
    "                eps_generic['quarter'] = quarters[j]\n",
    "                eps_generic['Ticker'] = browser.find_element_by_class_name('release-header-information-title').text\n",
    "                eps_generic['Company Name'] = browser.find_element_by_class_name('release-header-information-description').text\n",
    "                eps_generic['Name'] = analysts_generic[generic_count].text.split('\\n')[0]\n",
    "                eps_generic['Type'] = \"Generic\"\n",
    "                eps_generic['Estimated Value'] = values_generic[generic_count].text\n",
    "                eps [len(eps)] = eps_generic\n",
    "\n",
    "            analysts = browser.find_elements_by_class_name('username')\n",
    "            analysts_values = browser.find_elements_by_class_name('estimates-tbl-eps')\n",
    "\n",
    "            for analyst_count in range(len(analysts)):\n",
    "                eps_Analyst = {}\n",
    "                eps_Analyst['quarter'] = quarters[j]\n",
    "                eps_Analyst['Ticker'] = browser.find_element_by_class_name('release-header-information-title').text\n",
    "                eps_Analyst['Company Name'] = browser.find_element_by_class_name('release-header-information-description').text\n",
    "                eps_Analyst['Name'] = analysts[analyst_count].text\n",
    "                eps_Analyst['Type'] = \"Analyst\"\n",
    "                eps_Analyst['Estimated Value'] = analysts_values[analyst_count].text\n",
    "\n",
    "                eps [len(eps)] = eps_Analyst\n",
    "\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract EPS information and create Data/JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_info = scrape_eps(browser)\n",
    "\n",
    "with open('EPS_Info.json', 'w') as outfile:\n",
    "    json.dump(eps_info, outfile, indent=4)\n",
    "\n",
    "df=pd.DataFrame(eps_info)\n",
    "df_trans = df.T\n",
    "df_trans.to_csv('EPS_Info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates from List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_dup(duplicate):\n",
    "    final_list = []\n",
    "    \n",
    "    for num in range(len(duplicate)):\n",
    "        if duplicate[num] not in final_list:\n",
    "            final_list.append(duplicate[num])\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract All Analyst URLs from the Ticker Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_analysts_list(browser):\n",
    "    \n",
    "    ana_list = {}\n",
    "    for i in range(len(tickers)):\n",
    "        for j in range(len(quarters)):\n",
    "            url = 'https://www.estimize.com/'+tickers[i]+ '/' + quarters[j] + '?metric_name=eps&chart=historical'\n",
    "            browser.get(url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            analysts = browser.find_elements_by_class_name('username')\n",
    "\n",
    "    # Get the list of users for a specific Ticker\n",
    "            lnks=browser.find_elements_by_tag_name(\"a\")\n",
    "\n",
    "            # traverse list\n",
    "\n",
    "            for lnk in lnks:\n",
    "               # get_attribute() to get all href\n",
    "                if (lnk.get_attribute('href') != None):\n",
    "                    if ( '/users/' in lnk.get_attribute('href')):\n",
    "                        if ('sign_out' not in lnk.get_attribute('href')):\n",
    "                            ana_list[len(ana_list)] = lnk.get_attribute('href')\n",
    "\n",
    "    ana_list_final = Remove_dup(ana_list)\n",
    "    print (len(ana_list_final))\n",
    "\n",
    "    return ana_list_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Analyst information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_analysts_info(browser):\n",
    "\n",
    "    analysts_url = scrape_analysts_list(browser)\n",
    "    analyst_Profile = ['Error rate', 'Accuracy Percentile', 'Points', 'Points/Estimate', 'Stocks', 'Pending']\n",
    "    analysts_Overview_final = {}\n",
    "    for i in range(len(analysts_url)):\n",
    "        url = analysts_url[i]\n",
    "        browser.get(url)\n",
    "        time.sleep(1)\n",
    "#         print(url)\n",
    "        analyst_Overview = {}\n",
    "        try:\n",
    "            analyst_Overview['Name'] = browser.find_element_by_class_name('profile-display-name').text\n",
    "            analyst_Overview['User ID'] = browser.find_element_by_class_name('profile-username').text\n",
    "            # bio = browser.find_elements_by_class_name('profile-bio-categorizations')\n",
    "            analyst_Overview['roles'] = browser.find_element_by_class_name('profile-bio-categorizations').text\n",
    "            date = browser.find_element_by_class_name('profile-activity-stats').text.split (' ')\n",
    "            analyst_Overview['Join Date'] = date[2] + ' ' + date[3]\n",
    "            analyst_Overview['Analyst Confidence Score'] = browser.find_element_by_class_name('value').text\n",
    "\n",
    "            profile_stat = browser.find_elements_by_class_name('profile-stat')\n",
    "            for i in range (len(profile_stat)):\n",
    "                analyst_Overview[analyst_Profile[i]] = profile_stat[i].text\n",
    "           \n",
    "            analysts_Overview_final[len(analysts_Overview_final)+1] = analyst_Overview\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    return analysts_Overview_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Analyst information and create Data/JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775\n"
     ]
    }
   ],
   "source": [
    "analysts_info = scrape_analysts_info(browser)\n",
    "\n",
    "with open('Analysts_Info.json', 'w') as outfile:\n",
    "    json.dump(analysts_info, outfile, indent=4)\n",
    "\n",
    "df=pd.DataFrame(analysts_info)\n",
    "df_trans = df.T\n",
    "df_trans.to_csv('Analysts_Info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough Section with all trial codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.estimize.com/users/cantor_13'\n",
    "url = 'https://www.estimize.com/users/cantor_13'\n",
    "browser.get(url)\n",
    "time.sleep(1)\n",
    "analyst_Profile = ['Error rate', 'Accuracy Percentile', 'Points', 'Points/Estimate', 'Stocks', 'Pending']\n",
    "\n",
    "analyst_Overview = {}\n",
    "analyst_Overview['Name'] = browser.find_element_by_class_name('profile-display-name').text\n",
    "analyst_Overview['User ID'] = browser.find_element_by_class_name('profile-username').text\n",
    "# bio = browser.find_elements_by_class_name('profile-bio-categorizations')\n",
    "analyst_Overview['roles'] = browser.find_element_by_class_name('profile-bio-categorizations').text\n",
    "date = browser.find_element_by_class_name('profile-activity-stats').text.split (' ')\n",
    "analyst_Overview['Join Date'] = date[2] + ' ' + date[3]\n",
    "analyst_Overview['Analyst Confidence Score'] = browser.find_element_by_class_name('value').text\n",
    "\n",
    "profile_stat = browser.find_elements_by_class_name('profile-stat')\n",
    "\n",
    "\n",
    "for i in range (len(profile_stat)):\n",
    "    analyst_Overview[analyst_Profile[i]] = profile_stat[i].text\n",
    "#     print (profile_stat[i].text)\n",
    "\n",
    "# print (analyst_Overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Show 20 more\n",
      "Show 20 more\n",
      "Ticker Quarter Reports Published EPS Revenue\n",
      "HQY Q3 2022 Dec 6, 2021 AMC Oct 4, 2021 62 days ago 0.34 184.00\n",
      "UNH Q4 2021 Jan 18, 2022 BMO Oct 14, 2021 52 days ago 4.31 71.60\n",
      "ANTM Q4 2021 Jan 26, 2022 BMO Oct 20, 2021 46 days ago 5.01 37.10\n",
      "NXGN Q3 2022 Jan 27, 2022 AMC Oct 28, 2021 38 days ago 0.24 144.90\n",
      "HUM Q4 2021 Feb 2, 2022 BMO Nov 3, 2021 32 days ago 1.18 21.10\n",
      "CHNG Q3 2022 Feb 2, 2022 BMO Aug 5, 2021 122 days ago 0.39 873.00\n",
      "CI Q4 2021 Feb 3, 2022 BMO Nov 5, 2021 4.65 43.70\n",
      "OMCL Q4 2021 Feb 3, 2022 BMO Nov 2, 2021 0.94 309.30\n",
      "PINC Q2 2022 Feb 7, 2022 BMO Nov 2, 2021 33 days ago 0.66 354.50\n",
      "CERN Q4 2021 Feb 8, 2022 BMO Nov 1, 2021 0.89 1,485\n",
      "CNC Q4 2021 Feb 8, 2022 BMO Oct 26, 2021 0.96 31.90\n",
      "CVS Q4 2021 Feb 9, 2022 BMO Nov 3, 2021 1.56 73.10\n",
      "VCRA Q4 2021 Feb 10, 2022 AMC Oct 28, 2021 0.15 63.60\n",
      "CPSI Q4 2021 Feb 10, 2022 AMC Nov 9, 2021 0.62 71.40\n",
      "MDRX Q4 2021 Feb 17, 2022 AMC Nov 4, 2021 0.24 389.00\n",
      "HSTM Q4 2021 Feb 22, 2022 AMC Oct 26, 2021 40 days ago -0.01 64.10\n",
      "BNFT Q4 2021 Feb 23, 2022 AMC Mar 8, 2021 272 days ago 0.15 73.20\n",
      "EHTH Q4 2021 Feb 24, 2022 BMO Nov 8, 2021 1.02 269.90\n",
      "TVTY Q4 2021 Feb 24, 2022 AMC Nov 2, 2021 0.36 125.80\n",
      "EVH Q4 2021 Mar 1, 2022 AMC Nov 3, 2021 0.01 231.10\n",
      "TDOC Q4 2021 Mar 2, 2022 AMC Oct 27, 2021 542.60\n",
      "RCM Q4 2021 Mar 11, 2022 BMO Nov 2, 2021 33 days ago 0.10 394.08\n",
      "HQY Q4 2022 Mar 21, 2022 AMC Oct 4, 2021 62 days ago 0.37 200.40\n",
      "PINC Q3 2022 May 9, 2022 BMO Nov 2, 2021 0.67 348.50\n",
      "NXGN Q4 2022 May 20, 2022 AMC Oct 28, 2021 38 days ago 0.16 148.70\n",
      "Ticker Quarter Reported Rank EPS Points Revenue Points Total Points\n",
      "CPSI Q3 2021 Nov 9, 2021 1 / 10 -3 17 14\n",
      "EHTH Q3 2021 Nov 8, 2021 1 / 5 -3 10 7\n",
      "MDRX Q3 2021 Nov 4, 2021 4 / 6 -6 13 7\n",
      "CI Q3 2021 Nov 4, 2021 9 / 9 -4 -25 -29\n",
      "EVH Q3 2021 Nov 3, 2021 1 / 7 25 21 46\n",
      "BNFT Q3 2021 Nov 3, 2021 3 / 3 -12 -6 -18\n",
      "HUM Q3 2021 Nov 3, 2021 8 / 8 -8 -25 -33\n",
      "CVS Q3 2021 Nov 3, 2021 35 / 35 -9 -25 -34\n",
      "CHNG Q2 2022 Nov 3, 2021 1 / 3 25 25 50\n",
      "TVTY Q3 2021 Nov 2, 2021 5 / 5 8 -9 -1\n",
      "OMCL Q3 2021 Nov 2, 2021 5 / 5 7 -4 3\n",
      "PINC Q1 2022 Nov 2, 2021 4 / 5 12 -5 7\n",
      "RCM Q3 2021 Nov 2, 2021 4 / 4 -5 -4 -9\n",
      "CERN Q3 2021 Oct 29, 2021 7 / 7 -5 -6 -11\n",
      "NXGN Q2 2022 Oct 28, 2021 6 / 6 -5 -7 -12\n",
      "VCRA Q3 2021 Oct 28, 2021 4 / 4 9 9 18\n",
      "TDOC Q3 2021 Oct 27, 2021 24 / 35 -5 -5\n",
      "CNC Q3 2021 Oct 26, 2021 11 / 11 -8 -25 -33\n",
      "HSTM Q3 2021 Oct 25, 2021 4 / 4 -9 -9 -18\n",
      "ANTM Q3 2021 Oct 20, 2021 12 / 12 -15 -25 -40\n",
      "UNH Q3 2021 Oct 14, 2021 33 / 34 -4 -25 -29\n",
      "HQY Q2 2022 Sep 8, 2021 5 / 5 -7 -7 -14\n",
      "PINC Q4 2021 Aug 17, 2021 2 / 3 -5 10 5\n",
      "MDRX Q2 2021 Aug 5, 2021 5 / 6 -5 -3 -8\n",
      "CI Q2 2021 Aug 5, 2021 8 / 8 9 -25 -16\n"
     ]
    }
   ],
   "source": [
    "# url = 'https://www.estimize.com/users/cantor_13'\n",
    "url = 'https://www.estimize.com/users/cantor_13'\n",
    "browser.get(url)\n",
    "time.sleep(10)\n",
    "analyst_Profile = ['Error rate', 'Accuracy Percentile', 'Points', 'Points/Estimate', 'Stocks', 'Pending']\n",
    "\n",
    "analyst_Overview = {}\n",
    "analyst_Overview['Name'] = browser.find_element_by_class_name('profile-display-name').text\n",
    "analyst_Overview['User ID'] = browser.find_element_by_class_name('profile-username').text\n",
    "\n",
    "element = browser.find_elements_by_partial_link_text(\" more\")\n",
    "element.pop(len(element)-1)\n",
    "\n",
    "print(len(element))\n",
    "for i in range (len(element)):\n",
    "    print(element[i].text)\n",
    "    element[i].click()\n",
    "\n",
    "# element1=browser.find_element(By.ID,\"profile-covered-stocks-wrap\")\n",
    "# print (element1.text)\n",
    "# element.send_keys(\"typing\")\n",
    "\n",
    "\n",
    "\n",
    "# profile_Covered_Stocks_wrap = browser.find_element_by_class_name('profile-covered-stocks-wrap')\n",
    "# print (len(profile_Covered_Stocks_wrap))\n",
    "\n",
    "# profile_Covered_Stocks = browser.find_elements_by_class_name('linked-table-container')\n",
    "profile_Covered_Stocks_head = browser.find_elements_by_class_name('thead')\n",
    "profile_Covered_Stocks_body = browser.find_elements_by_class_name('tbody')\n",
    "# print (len(profile_Covered_Stocks))\n",
    "# print (len(profile_Covered_Stocks_head))\n",
    "# print (len(profile_Covered_Stocks_body))\n",
    "\n",
    "Covered_Columns = profile_Covered_Stocks_head[0].text.split(' ')\n",
    "Covered_Rows = profile_Covered_Stocks_body[0].text.split(' ')\n",
    "\n",
    "# print (Covered_Columns)\n",
    "# print (Covered_Rows)\n",
    "# overview['Sectors'] = sectors.text.split('›')[0]\n",
    "#             overview['Industries'] = sectors.text.split('›')[1]\n",
    "\n",
    "for i in range (len(profile_Covered_Stocks_head)):\n",
    "#     print (profile_Covered_Stocks[i].text)\n",
    "#     analyst_Overview[analyst_Profile[i]] = profile_stat[i].text\n",
    "    print (profile_Covered_Stocks_head[i].text)\n",
    "# #     for j in range (len(profile_Covered_Stocks_body)):\n",
    "    print (profile_Covered_Stocks_body[i].text)\n",
    "# print (profile_Covered_Stocks[0].text)\n",
    "\n",
    "# analyst_Overview\n",
    "\n",
    "# print (bio[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_read_csv_file():\n",
    "    ticker_full = {}\n",
    "    with open('C:/Personal/Shreya/MS/DBNMS/msa8040_final_project_ticker_list.csv', 'r') as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "#         print (len(csvReader))\n",
    "    for row in csvReader:\n",
    "        ticker_full = row\n",
    "#         print(row)\n",
    "    return ticker_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-31ee72585589>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mticker_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_read_csv_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print (ticker_full)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-65dc4e1badd0>\u001b[0m in \u001b[0;36mtest_read_csv_file\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcsvReader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvDataFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#         print (len(csvReader))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsvReader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mticker_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#         print(row)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "ticker_full = test_read_csv_file()\n",
    "print(len(ticker_full))\n",
    "# print (ticker_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
